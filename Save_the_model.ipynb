{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjWShtiZldtBvDTILKghPM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kishan20-00/Saving_the_existing_model/blob/main/Save_the_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing packages\n"
      ],
      "metadata": {
        "id": "X6TWpGf-Ruvd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAOikyw4Rhnl",
        "outputId": "cda559b5-35f8-44e8-8287-1bffbf109034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.8/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_hub) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_hub) (3.19.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.8/dist-packages (4.8.2)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.14.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (5.4.8)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (3.19.6)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (0.3.6)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (2.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (5.12.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (7.1.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.12.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (4.64.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (0.1.8)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.14.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from promise->tensorflow_datasets) (1.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.58.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U tensorflow_hub\n",
        "!pip install -U tensorflow_datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "_YULFuRmRuCF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Load the Cats vs Dogs Dataset"
      ],
      "metadata": {
        "id": "h98JvH955Md5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_examples, validation_examples), info = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")"
      ],
      "metadata": {
        "id": "FWHMDWz95QTI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_image(image, label):\n",
        "  # `hub` image modules exepct their data normalized to the [0,1] range.\n",
        "  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
        "  return  image, label\n",
        "\n",
        "num_examples = info.splits['train'].num_examples\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_RES = 224\n",
        "\n",
        "train_batches      = train_examples.cache().shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_examples.cache().map(format_image).batch(BATCH_SIZE).prefetch(1)"
      ],
      "metadata": {
        "id": "pux2DHpT5TBg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Transfer Learning with TensorFlow Hub"
      ],
      "metadata": {
        "id": "WcqtoY8c5YvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "feature_extractor = hub.KerasLayer(URL,\n",
        "                                   input_shape=(IMAGE_RES, IMAGE_RES,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1hBGigJ5fxT",
        "outputId": "8df0c9d2-a516-481b-d0b0-274b36b4e2fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor.trainable = False"
      ],
      "metadata": {
        "id": "vK-UPyeS5jIY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attach a classification head"
      ],
      "metadata": {
        "id": "ED7OI0a85nZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  feature_extractor,\n",
        "  layers.Dense(2)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUDYe1Jy5qzF",
        "outputId": "261e6f6e-5d82-4124-862b-10f7cb74c781"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,260,546\n",
            "Trainable params: 2,562\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "URNLdJqC5t0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  optimizer='adam', \n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 3\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=validation_batches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I7-dwyu5vTU",
        "outputId": "9cdd0367-fe10-4428-d834-c194d4cd90fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "582/582 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.9806"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the predictions"
      ],
      "metadata": {
        "id": "r3cTeIFD6iBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = np.array(info.features['label'].names)\n",
        "class_names"
      ],
      "metadata": {
        "id": "cqM6towc6kLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch, label_batch = next(iter(train_batches.take(1)))\n",
        "image_batch = image_batch.numpy()\n",
        "label_batch = label_batch.numpy()\n",
        "\n",
        "predicted_batch = model.predict(image_batch)\n",
        "predicted_batch = tf.squeeze(predicted_batch).numpy()\n",
        "predicted_ids = np.argmax(predicted_batch, axis=-1)\n",
        "predicted_class_names = class_names[predicted_ids]\n",
        "predicted_class_names"
      ],
      "metadata": {
        "id": "TBJyAxEM6omA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Labels: \", label_batch)\n",
        "print(\"Predicted labels: \", predicted_ids)"
      ],
      "metadata": {
        "id": "PmGdNBRM6sMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(image_batch[n])\n",
        "  color = \"blue\" if predicted_ids[n] == label_batch[n] else \"red\"\n",
        "  plt.title(predicted_class_names[n].title(), color=color)\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (blue: correct, red: incorrect)\")"
      ],
      "metadata": {
        "id": "uP_oAdpl6zxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Save as Keras .h5 model"
      ],
      "metadata": {
        "id": "XNp-_vxi61PV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = time.time()\n",
        "\n",
        "export_path_keras = \"./{}.h5\".format(int(t))\n",
        "print(export_path_keras)\n",
        "\n",
        "model.save(export_path_keras)"
      ],
      "metadata": {
        "id": "yOjpChgH66VP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "Asv8HCQv69OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4: Load the Keras .h5 model"
      ],
      "metadata": {
        "id": "IeRF6Vck6-lN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reloaded = tf.keras.models.load_model(\n",
        "  export_path_keras, \n",
        "  # `custom_objects` tells keras how to load a `hub.KerasLayer`\n",
        "  custom_objects={'KerasLayer': hub.KerasLayer})\n",
        "\n",
        "reloaded.summary()"
      ],
      "metadata": {
        "id": "De9mAehx7Bq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_batch = model.predict(image_batch)\n",
        "reloaded_result_batch = reloaded.predict(image_batch)"
      ],
      "metadata": {
        "id": "3-5-QNmh7DvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(abs(result_batch - reloaded_result_batch)).max()"
      ],
      "metadata": {
        "id": "53FBnw3n7FmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keep training"
      ],
      "metadata": {
        "id": "ejFt1Ei67UVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 3\n",
        "history = reloaded.fit(train_batches,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=validation_batches)"
      ],
      "metadata": {
        "id": "3dlLLt5r7WCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 5: Export as SavedModel"
      ],
      "metadata": {
        "id": "Ty4b74Ki7Yor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = time.time()\n",
        "\n",
        "export_path_sm = \"./{}\".format(int(t))\n",
        "print(export_path_sm)\n",
        "\n",
        "tf.saved_model.save(model, export_path_sm)"
      ],
      "metadata": {
        "id": "UBq8IDNa7bxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {export_path_sm}"
      ],
      "metadata": {
        "id": "SGha7z3Q7fU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 6: Load SavedModel"
      ],
      "metadata": {
        "id": "na2eaISp7gmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reloaded_sm = tf.saved_model.load(export_path_sm)"
      ],
      "metadata": {
        "id": "Q5OrCfLD7jvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reload_sm_result_batch = reloaded_sm(image_batch, training=False).numpy()"
      ],
      "metadata": {
        "id": "KdA_ErHZ7nfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(abs(result_batch - reload_sm_result_batch)).max()"
      ],
      "metadata": {
        "id": "ArPSK1e_7pkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 7: Loading the SavedModel as a Keras Model"
      ],
      "metadata": {
        "id": "a5X3sK4v7qIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = time.time()\n",
        "\n",
        "export_path_sm = \"./{}\".format(int(t))\n",
        "print(export_path_sm)\n",
        "tf.saved_model.save(model, export_path_sm)"
      ],
      "metadata": {
        "id": "zq2IhT107wkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reload_sm_keras = tf.keras.models.load_model(\n",
        "  export_path_sm,\n",
        "  custom_objects={'KerasLayer': hub.KerasLayer})\n",
        "\n",
        "reload_sm_keras.summary()"
      ],
      "metadata": {
        "id": "IWuCw0l67ykE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_batch = model.predict(image_batch)\n",
        "reload_sm_keras_result_batch = reload_sm_keras.predict(image_batch)"
      ],
      "metadata": {
        "id": "fk_57ooy71H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(abs(result_batch - reload_sm_keras_result_batch)).max()"
      ],
      "metadata": {
        "id": "EiqJ4rsP710G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 8: Download your model"
      ],
      "metadata": {
        "id": "y1oLLDob75gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r model.zip {export_path_sm}"
      ],
      "metadata": {
        "id": "li5yuil678Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "2VF5Cy1_8Aes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('./model.zip')\n",
        "except ImportError:\n",
        "  pass"
      ],
      "metadata": {
        "id": "bysr7cOt8DIY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}